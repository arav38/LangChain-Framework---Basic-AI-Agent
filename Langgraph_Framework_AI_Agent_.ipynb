{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPJU/nK03SS1NjNyn0s1yQI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arav38/LangChain-Framework---Basic-AI-Agent/blob/main/Langgraph_Framework_AI_Agent_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph langchain_community langchain_community langchain langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsqAK6-U0IDu",
        "outputId": "d3f620e3-42be-4433-ff87-43945a19a633"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.4.9-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.26-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.3.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.66)\n",
            "Collecting langgraph-checkpoint>=2.0.26 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.2.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.70-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.1)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Collecting groq<1,>=0.28.0 (from langchain-groq)\n",
            "  Downloading groq-0.28.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.5.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.28.0->langchain-groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.28.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.28.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.28.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.28.0->langchain-groq) (4.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint>=2.0.26->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.28.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.28.0->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langgraph-0.4.9-py3-none-any.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.5/152.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.26-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-0.3.4-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading groq-0.28.0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.2.2-py3-none-any.whl (23 kB)\n",
            "Downloading langgraph_sdk-0.1.70-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, ormsgpack, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, langgraph-sdk, groq, dataclasses-json, langgraph-checkpoint, langchain-groq, langgraph-prebuilt, langgraph, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 groq-0.28.0 httpx-sse-0.4.1 langchain-groq-0.3.4 langchain_community-0.3.26 langgraph-0.4.9 langgraph-checkpoint-2.1.0 langgraph-prebuilt-0.2.2 langgraph-sdk-0.1.70 marshmallow-3.26.1 mypy-extensions-1.1.0 ormsgpack-1.10.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nx0q32X7z8wy"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph import START,END\n",
        "from langchain import chat_models, LLMChain, PromptTemplate\n",
        "from langchain.schema import BaseOutputParser\n",
        "from langchain_groq import ChatGroq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(model =\"meta-llama/llama-4-scout-17b-16e-instruct\",api_key='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')"
      ],
      "metadata": {
        "id": "5JrrWuKS1MxZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq-qbMMW1Q2f",
        "outputId": "07a60611-1364-4471-8824-248f26763c6e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7c56d5ca2850>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7c56d58d7a90>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', model_kwargs={}, groq_api_key=SecretStr('**********'))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get data from wikipedia"
      ],
      "metadata": {
        "id": "aOICW6pp2kaw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIRGYNPr2ogR",
        "outputId": "1897e8fd-bab5-4613-fe6b-46bd6dee38ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.6.15)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (4.14.0)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=3e0ee1630c5578ae0f8a4b75ae20a2163ad751beb7f7b7ec0144bf76177ad663\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import WikipediaQueryRun\n",
        "from langchain.utilities import WikipediaAPIWrapper"
      ],
      "metadata": {
        "id": "-sPrOZMV2yML"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wikipedia_tool =  WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())"
      ],
      "metadata": {
        "id": "cVzYVkUq2-kE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool"
      ],
      "metadata": {
        "id": "J8V1U2q34HzE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wikipedia_agent =  Tool.from_function(\n",
        "    name ='wikipendi_agent',\n",
        "    func=wikipedia_tool.run,\n",
        "    description='useful for when you need to answer question about current affairs '\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "xV-pLLZ-4rwl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.utilities import OpenWeatherMapAPIWrapper\n",
        "# from langchain.tools import"
      ],
      "metadata": {
        "id": "uSK5Ff5_5K5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wikipedia_agent.run(\"Whos Donald Trump\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "H69wQe-y6X3_",
        "outputId": "e4694b3b-04db-4600-bea0-ab4df22d78e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Page: Trump family\\nSummary: The Trump family is the prominent wealthy family of US President Donald Trump. The family is of Bavarian German and Scottish descent. They are active in business, entertainment, politics, and real estate. Prominent members such as the President\\'s grandfather Friedrich Trump and his father Fred Trump are grouped here.\\n\\nPage: Donald Trump Jr.\\nSummary: Donald John Trump Jr. (born December 31, 1977), often nicknamed Don Jr., is an American businessman and political activist. He is the eldest child of U.S. president Donald Trump and his first wife Ivana.\\nTrump serves as a trustee and executive vice president of the Trump Organization, running the company alongside his younger brother Eric. During their father\\'s first presidency, the brothers continued to engage in deals and investments in foreign countries and collect payments at their U.S. properties from foreign governments, despite pledging not to do so. He also served as a boardroom judge on the reality TV show featuring his father, The Apprentice. In addition, he authored Triggered in 2019 and Liberal Privilege in 2020.\\nTrump was active in his father\\'s 2016 presidential campaign. He had a meeting with a Russian lawyer who promised damaging information about the campaign of Hillary Clinton in the 2016 presidential election. Trump campaigned for several Republicans during the 2018 midterm elections. He has promoted several conspiracy theories.\\nTrump was also active in his father\\'s 2020 presidential campaign, often being on the campaign trail and being featured in the news for making unfounded claims. During the election he called for \"total war\" as the results were counted and promoted the stolen election conspiracy theory. Following his father\\'s defeat, he engaged in attempts to overturn the results. He spoke at the rally that led to the storming of the Capitol, where he threatened Trump\\'s opponents that \"we\\'re coming for you.\" In January 2021, Attorney General for the District of Columbia Karl Racine said that he is looking at whether to charge Donald Trump Jr. with inciting the violent attack on the U.S. Capitol in the criminal investigation into the attack. CNN reported in April 2022 that two days after the election, Trump Jr. sent a text message to White House Chief of Staff Mark Meadows outlining paths to subvert the Electoral College process and ensure his father a second term.\\nAt the 2024 Republican National Convention, he led the introductions of JD Vance, who had been selected as Donald Trump\\'s running mate.\\n\\nPage: First presidency of Donald Trump\\nSummary: Donald Trump\\'s first tenure as the president of the United States began on January 20, 2017, when Trump was inaugurated as the 45th president, and ended on January 20, 2021. Trump, a Republican from New York, took office following his electoral college victory over Democratic nominee Hillary Clinton in the 2016 presidential election. Upon his inauguration, he became the first president in American history without prior public office or military background. Trump made an unprecedented number of false or misleading statements during his 2016 campaign and first presidency. Alongside Trump\\'s presidency, the Republican Party also held their majorities in the House of Representatives under Speaker Paul Ryan and the Senate under Senate Majority Leader Mitch McConnell during the 115th U.S. Congress. His first presidency ended following his defeat in the 2020 presidential election to former Democratic vice president Joe Biden, after his first term in office.\\nTrump was unsuccessful in his efforts to repeal the Affordable Care Act but rescinded the individual mandate. He sought substantial spending cuts to major welfare programs, including Medicare and Medicaid. Trump signed the Tax Cuts and Jobs Act of 2017 and a partial repeal of the Dodd–Frank Act. He appointed Neil Gorsuch, Brett Kavanaugh, and Amy Coney Barrett to the Supreme Court. Trump reversed numerous environmental regulations, withdrew fro'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yvUnt3DZ7bsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "4BvPqGRk7kZo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intent_prompt = PromptTemplate.from_template(\"\"\"\n",
        "Classify the following user input into one of the categories: insurance, finance, wikipedia, fallback.\n",
        "\n",
        "User input: {input}\n",
        "Category:\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "LpoRO6Rd8hU5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def route_intent(input_text):\n",
        "  input_prompt = intent_prompt.format(input_text)\n",
        "  responce =llm.predict(input_prompt).strip().lower()\n",
        "  return responce"
      ],
      "metadata": {
        "id": "f6G1Tzpw9V-p"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LMv28l-AB6qb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import START,END\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "from pydantic import BaseModel,Field\n",
        "from typing import Literal"
      ],
      "metadata": {
        "id": "E2v-JthuCAQo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal\n",
        "\n",
        "class MessageClassifier(BaseModel):\n",
        "    message_type: Literal[\"Insurance\", \"Medical\", \"Financial\", \"Wikepedia\"] = Field(\n",
        "        ...,\n",
        "        description=\"Classify message whether it is insurance, medical, financial or wikipedia\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "7afEQiS6EjNU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aBZXbbPo_eVC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "  message : Annotated[list,add_messages]\n",
        "  message_type : str | None"
      ],
      "metadata": {
        "id": "kMaPeHXaCsYs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def router(state: State):\n",
        "    message_type = state.get(\"message_type\", \"Wikipedia\")\n",
        "    if message_type == \"Financial\":\n",
        "        return {\"next\": \"Financial\"}\n",
        "    elif message_type == \"Insurance\":\n",
        "        return {\"next\": \"Insurance\"}\n",
        "    elif message_type == \"Medical\":\n",
        "        return {\"next\": \"Medical\"}\n",
        "\n",
        "    return {\"next\": \"Wikipedia\"}"
      ],
      "metadata": {
        "id": "nZCeDyAl9EaY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def message_classify(state:State):\n",
        "\n",
        "  last_message = state[\"message\"][-1]\n",
        "  classifier_llm = llm.with_structured_output(MessageClassifier)\n",
        "\n",
        "  result = llm.invoke([\n",
        "      {\"role\":\"system\",\"context\":\"\"\"Classify user message either Insurance Related, Medical Related , Finanacial Related or Current Affair related\n",
        "           Insurance Related - If it ask about insurance then please answer question with maximum accuracy based on data\n",
        "           Finanacial Related - if it asked about finance then please answer question with maximum accuracy based on data\n",
        "           Medical Related - if it asked about medical then please answer question based on data with maximum accuracy\n",
        "           Wikipendia - Please classify question based\n",
        "             \"\"\"\n",
        "           },\n",
        "        {\"role\":\"user\",\"context\":last_message.content}\n",
        "])\n",
        "\n",
        "  return {\"message_type\":result.message_type}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def classify_message(state:State):\n",
        "\n",
        "  return {\"message_type\":result.content}\n",
        "\n"
      ],
      "metadata": {
        "id": "Q2VOMrxP_eD8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ooyP7-hy9j7o"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from decimal import Context\n",
        "def insurace_bot():\n",
        "\n",
        "  last_message = State[\"message\"][-1]\n",
        "\n",
        "  message = [\n",
        "      {\"role\":\"system\",\n",
        "      \"context\": \"\"\" You are an intelligent and helpful insurance assistant. You help users understand and manage their insurance policies, claims, and benefits. Always respond clearly, professionally, and accurately.\n",
        "      \"\"\"},\n",
        "      {\n",
        "      \"role\":\"user\",\n",
        "      \"context\" : last_message.content}\n",
        "  ]\n",
        "\n",
        "  reply = llm.invoke(message)\n",
        "\n",
        "  return {\"Message\":[{\"role\":\"user\",\"Context\":reply.content}]}"
      ],
      "metadata": {
        "id": "pRe3wt8e66cm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def medical_bot():\n",
        "\n",
        "  last_message = State[\"message\"][-1]\n",
        "\n",
        "  message = [\n",
        "      {\"role\":\"system\",\n",
        "      \"context\": \"\"\" You are an intelligent and helpful Medical assistant. You help users understand and manage their insurance policies, claims, and benefits. Always respond clearly, professionally, and accurately.\n",
        "      \"\"\"},\n",
        "      {\n",
        "      \"role\":\"user\",\n",
        "      \"context\" : last_message.content}\n",
        "  ]\n",
        "\n",
        "  reply = llm.invoke(message)\n",
        "\n",
        "  return {\"Message\":[{\"role\":\"user\",\"Context\":reply.content}]}"
      ],
      "metadata": {
        "id": "cvEeOGQr7ReZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def financial_bot():\n",
        "\n",
        "\n",
        "  last_message = State[\"message\"][-1]\n",
        "\n",
        "  message = [\n",
        "      {\"role\":\"system\",\n",
        "      \"context\": \"\"\" You are an intelligent and helpful Financial assistant. You help users understand and manage their insurance policies, claims, and benefits. Always respond clearly, professionally, and accurately.\n",
        "      \"\"\"},\n",
        "      {\n",
        "      \"role\":\"user\",\n",
        "      \"context\" : last_message.content}\n",
        "  ]\n",
        "\n",
        "  reply = llm.invoke(message)\n",
        "\n",
        "  return {\"Message\":[{\"role\":\"user\",\"Context\":reply.content}]}\n"
      ],
      "metadata": {
        "id": "uWodqNOuL5lQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import stat\n",
        "graph_builder = StateGraph(State)"
      ],
      "metadata": {
        "id": "kQYgmJuqC8pB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_node(\"Classifier\",MessageClassifier)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKFuxMomNpm9",
        "outputId": "c903c91c-00bf-4bef-ecce-6c9ca8726237"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7c56d51a3590>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_node(\"router\",router)\n",
        "graph_builder.add_node(\"Wikiepedia\",wikipedia_agent)\n",
        "graph_builder.add_node(\"Insurance\",insurace_bot)\n",
        "graph_builder.add_node(\"Medical\",medical_bot)\n",
        "graph_builder.add_node(\"Financial\",financial_bot)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1JILvW-E6_Q",
        "outputId": "bffd0f21-e34b-4d03-d419-4377ef056506"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7c56d51a3590>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(START,\"Classifier\")\n",
        "graph_builder.add_edge(\"Classifier\",\"router\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4QjoHbqFWBJ",
        "outputId": "9f9a6989-fd24-43b4-de3e-e54812fcddc3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7c56d51a3590>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_conditional_edges('router',lambda state:state.get(\"Next\"),\n",
        "                                   { \"Insurance\":\"Insurance\",\"Medical\":\"Medical\",\"Financial\":\"Financial\",\"Wikiepedia\":\"Wikiepedia\", None: END})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--1R9gFPGHhl",
        "outputId": "f29bec3e-1a12-48e5-d0cf-61f969a65ae8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7c56d51a3590>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(\"Wikiepedia\",END)\n",
        "graph_builder.add_edge(\"Insurance\",END)\n",
        "graph_builder.add_edge(\"Medical\",END)\n",
        "graph_builder.add_edge(\"Financial\",END)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwG0FoJBAsv7",
        "outputId": "bdb9e846-bcda-4e96-c415-e6d6e022209c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7c56d51a3590>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "7kHkHQlOA0nK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_chatbot():\n",
        "    # Initialize state according to AgentState definition\n",
        "    state = {\"messages\": []} # Removed message_type\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"Message: \")\n",
        "        if user_input == \"exit\":\n",
        "            print(\"Bye\")\n",
        "            break\n",
        "\n",
        "        # Ensure updates conform to AgentState\n",
        "        state[\"messages\"] = state.get(\"messages\", []) + [\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ]\n",
        "\n",
        "        # The 'next' key will be managed by the graph's conditional edges\n",
        "\n",
        "        try:\n",
        "            state = graph.invoke(state)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during graph invocation: {e}\")\n",
        "            # Optionally, print the state to help with debugging\n",
        "            # print(f\"Current state before error: {state}\")\n",
        "            continue # Continue the loop to allow more input or exit\n",
        "\n",
        "        if state.get(\"messages\") and len(state[\"messages\"]) > 0:\n",
        "            last_message = state[\"messages\"][-1]\n",
        "            # Check if last_message is a dictionary with 'content' key\n",
        "            if isinstance(last_message, dict) and 'content' in last_message:\n",
        "                 print(f\"Assistant: {last_message['content']}\")\n",
        "            else:\n",
        "                 # If the message format is unexpected, print the whole message object\n",
        "                 print(f\"Assistant (raw message): {last_message}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVEcPw0JA4DD",
        "outputId": "0a0944f4-e563-440c-eae9-46d155ca15a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message: hello\n",
            "An error occurred during graph invocation: BaseModel.__init__() takes 1 positional argument but 2 were given\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n6HCqieoD6lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "4162177f",
        "outputId": "7d6bc544-720b-42de-86e7-c2e02b68da74"
      },
      "source": [
        "from typing import List, Tuple, Annotated, TypedDict\n",
        "\n",
        "from langgraph.graph.message import AnyMessage\n",
        "from langgraph.graph import add_message\n",
        "from langgraph.graph.state import StateGraph\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    # The list of messages exchanged between the user and the chatbot.\n",
        "    messages: Annotated[List[AnyMessage], add_message]\n",
        "    # The next node to visit\n",
        "    next: str"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'add_message' from 'langgraph.graph' (/usr/local/lib/python3.11/dist-packages/langgraph/graph/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-8cb79fbe27e4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnyMessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStateGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'add_message' from 'langgraph.graph' (/usr/local/lib/python3.11/dist-packages/langgraph/graph/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b489ccb6"
      },
      "source": [
        "# Assuming graph_builder is already defined, re-initialize it with AgentState\n",
        "# If graph_builder is not defined yet, use this to initialize it\n",
        "graph_builder = StateGraph(AgentState)\n",
        "\n",
        "# Now proceed with adding nodes and edges using this graph_builder\n",
        "# e.g., graph_builder.add_node(\"router\", router)\n",
        "#       graph_builder.add_edge(START, \"Classifier\")\n",
        "# ... and so on with the rest of your graph definition"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}